\section{Обзор подходов к извлечению аргументации}

\subsection{Обзор корпусов}
Задача извлечения аргументации решается в различных постановках. Общей идей является выделение компонент аргументации и определение связей между ними. Наиболее серьезные работы с применением машинного обучения, посвященные теме извлечения аргументации, датируются 2014 годом. В работах \cite{aharoni2014benchmark, rinott2015show} предлагается корпус аргументации на 2500 примеров. В качестве компонент аргументации рассматриваются три сущности:
\begin{itemize}
    \item Тема - короткая противоречивая фраза, определяющая центральный объект обсуждения (фокус).
    \item Контекстно-зависимое утверждение - краткая фраза, напрямую подтверждающая или опровергающая тему.
    \item Контекстно-зависимая предпосылка - участок текста, напрямую поддерживающий контекстно-зависимое утверждение в рамках данной темы.
\end{itemize}

Задача поставлена следующим образом - по заданной теме и коллекции текстов из википедии необходимо выделить контекстно-зависимые утверждения и предпосылки. Этап выделения компонент аргументации разделен на две подзадачи. Сначала предлагается выделить предложения, содержащие компоненты аргументации, после чего выделить непрервыне участки текста (фразы), которые являются непосредственно предпосылкой или утверждением. Таким образом решается задача выделения структуры аргументации. Как следует из определений, в данном корпусе отсутствует связь противоречия (атаки, противопоставления) между компонентами, поэтому отсутствует возможность выучить полемическую позицию аргумента. Стоит отметить, что задача выделения непрервыного участка текста в качестве компонент аргументации требует сложной разметки, из-за чего в следующих работах отказываются от этого этапа и решают задачу извлечения компонент на уровне предложений.

Дополнительно поставлена задача классификации предпосылок в три класса - прецедентные (Anecdotal), т.е. основанные на каком-либо случае; экспернтые (Expert), т.е. высказывание авторитетного источника; исследовательские (Study), т.е. результаты какого-либо научного исследования.



В работе \cite{shnarch2018will} предлагается новый корпус IBM Evidence Search размером 5700 примеров извлечения контекстно-зависимых предпосылок по темам. В данном корпусе происходит изменение постановки задачи. В предыдущих работах предпосылки имели связь с утверждениями, которые в свою очередь имели связь с темами, теперь предпосылки связаны напрямую с темами. В данном корпусе решается задача определения релевантности предпосылки по отношению к теме, т.е. решается задача извлечения структуры аргументации. В разметке отсутствует полемическая позиция предпосылки - поддержка или опровержение темы.

Предлагается два корпуса - SLD (strong labeled data, т.е. данные полученные с помощью человеческой экспертизы), а так же WLD (weak labeled data, т.е. данные, полученные автоматическими правилами), однако корпус WLD не предоставлен. В работе исследуется зависимость качества модели определения релевантности между предпосылкой и темой в зависимости от соотношения корпусов WLD и SLD. Показано, что использование данных, полученных автоматически повышает итоговое качество модели на несколько пунктов с 70\% до 72-74\% точности классификации, усредненной по темам.

В работе \cite{stab2018cross} предлагается корпус UKP Sentential Argument Mining Corpus. Рассматриваются пары сущностей "тема" и "утверждение", определяется наличие связи и ее тип. В отличие от предыдущих работ, тема не является противоречывым высказыванием, а вместо этого представляет собой центральный объект обсуждения (фокус). Утверждение является предложением, которое может как поддерживать или опровергать фокус, так и не иметь к нему отношения, что позволяет решать и задачу определения структуры аргументации и полемической позиции. Примеры: тема - "ядерная энергия", поддерживающее утверждение - "ядерная энергия уменьшает парниковый эффект". В корпусе представлено 25000 пар тем и утверждений по 8 темам. 

В работе исследуется способность моделей работать на новых темах, т.е. обобщать свои знания на домены, которые раньше не были выучены моделью. Несмотря на ограниченный набор тем, данный корпус одним из первых позволяет решать одновременно и задачу извлечения структуры аргументации и определения полемической позиции. Корпус отсутствует в открытом доступе.

В работе \cite{levy2018towards} подробнее описываются техники автоматического получения корпусов на примере задачи определения релевантности утверждения по отношению к теме. В качестве основного способа предлагается использовать правила, основанные на определенных лексических маркерах. Например предполагается, что часто встречаются шаблоны вида \textbf{<someone>argued that<claim>}. В корпусе отсутствует полемическая позиция и решается только задача определения структуры аргументации. В качестве замеров эффективности обученная на подобном корпусе модель замеряется на UKP Sentential Argument Mining Corpus и получает результаты сравнимые с моделями, предложенными в оригинальной работе.

Исследование \cite{bar2017stance} полностью посвещено задаче определения полемической позиции утверждений по отношению к теме. В корпусе IBM Claim Stance предоставлено 2400 пар тем и утверждений связанных отношением поддержки или атаки. Отсутствуют примеры утверждений не связанных с темами, поэтому отсутствует возможность извлечь структуру аргументации.


Отдельно стоит отметить и задачу определения качества аргументации, которой посвещен целый ряд работ \cite{gretz2020large, toledo2019automatic, gleize2019you}. В данной задаче необходимо определить качество утверждения по отношению к теме. Решение данной задачи позволяет отсортировать утверждения, чтобы использовать наиболее подходящие в целевой задаче. Сущестует несколько постановок данной задачи: присваивание утверждению некоторой величины от 0 до 1, отражающей его качество, или попарное сравнение двух утверждений с выбором наилучшего. 

В данных работах рассматриваются поддерживающие утверждения релевантные теме, поэтому невозможно обучить модель на этих корпусах ни определению полемической позиции, ни структуре аргументации, однако нельзя не отметить полезность подобного ранжирования в полномасштабной системе извлечения аргументации.

В работе \cite{toledo2020multilingual} предлагается два мультиязычных корпуса для извлечения аргументации. В первом корпусе ArgsEN было предоставлено 30000 пар тем и утверждений, у которых размечена полемическая позиция и качество аргумента. Помимо этого предоставлен корпус EviEN, состоящий из 35000 пар предпосылок, в котором размечена и полемическая позиция и релевантность.

Свой подход к аргументации развивается и в исследовательской команде Webis. В корпусе Webis Debate 16 \cite{webis16} предлагается классифицировать предложения в два класса - нейтральные и содержащие утверждение. В данной текстовой коллекции утверждения не привязаны к теме или любой другой компоненте аргументации; данная постановка не позволяет выделить ни структуру аргументации, ни полемическую позицию внутри нее.

Нельзя не внести в обзор и такую задачу как логический вывод (Textual Entailment, Natural Languge Inference). Данная задача напрямую не занимается извлечением аргументации, но задачи имеют схожую постановку: требуется по тексту и гипотезе понять отношение между ними. Видов отношений 3: нейтральное отношение, поддержка, противоречие. Примеры:
\begin{verbatim}
Текст: A man inspects the uniform of a figure in some East Asian country.
Гипотеза: The man is sleeping
Отношение: Contradiction

Текст: An older and younger man smilin
Гипотеза: Two men are smiling and laughing at the cats playing on the floor
Отношение: Neutral

Текст: A black race car starts up in front of a crowd of people
Гипотеза: A man is driving down a lonely road.
Отношение: Contradiction
\end{verbatim}

Задача NLI интересна тем, что как и в задачах извлечения аргументации присутствует несколько компонент (текст и гипотеза), между которыми необходимо найти связь. Вместо оригинальной постановки, в которй требовалось классифицировать отношение между двумя предложениями в 3 класса, можно факторизовать задачу в две подзадачи: определить релевантна ли гипотеза тексту, после чего определить при условии релевантности поддерживает ли или опровергается текст гипотезой. Данная формулировка очень похожа на этапы извлечения аргументации, а именно на извлечение структуры и последующее определение полемической позиции.

Существует несколько корпусов для решения подобной задачи: Stanford NLI \cite{snli:emnlp2015}, Multi-Genre NLI, TERRa. В отличие от корпусов аргументации, размер корпусов логического вывода измеряется не в тысячах примеров, а в сотнях тысяч. Более того, корпуса для этой задачи встречаются на нескольких языках, в том числе и русском.

Как было сказано в определении предпосылки, важно, чтобы предпосылка не являлась убеждением или верованием, а имела под собой веские основания. Во всех описанных выше корпусах, где предлагалось работать с предпосылками, предполагалось, что эта закономерность заложена в данные. В соревновании \textbf{CheckThat!} \cite{barron2020overview} при конференции CLEF с 2020 задача верификации предпосылок решается целенаправленно. В данном соревновании представлены следующие дорожки, собранные из данных социальной сети Twitter:
\begin{itemize}
    \item \textbf{Значимость (Check Worthiness)} - даны сообщения пользователей, необходимо отранжировать их по значимости, т.е. таким образом, чтобы на первых местах оказались те сообщения, которые необходимо верифицировать в первую очередь.
    \item \textbf{Выделение предпосылок (Claim Retrieval)} - дано утверждение, представляющее из себя некое сообщение из твиттера, и набор уже верифицированных утверждений. Необходимо отранжировать верифицированные утверждения, чтобы понять, можно ли с их помощью подтвердить целевое утверждение. Данный трек доступен только на арабском языке.
\end{itemize}

Похожим образом построен и корпус FEVER (Fact Extraction and VERification) \cite{thorne2018fever}. Необходимо по набору утверждений и статей из википедии найти участки текста, подтверждающие целевое утверждение.

В работе \cite{abbott2016internet} предоставляется Internet Argument Corpus v2. В данной коллекции размечены пары сообщений из интернет-форумов. Сообщения разбиты на пары-вопрос-ответ и размечены по следующим критериям:
\begin{enumerate}
    \item Согласие или несогласие - число от -5 до 5, отражающее полемическую позицию ответа к вопросу.
    \item Эмоциональность или факты - число от -5 до 5, отражающее насколько в ответе используются факты, а не эмоции и убеждения отвечающего.
    \item Сарказм - число от 0 до 1, отражающее число разметчиков, посчитавших ответ саркастичным, а не серьезным.
\end{enumerate}
Как видно из описания данный корпус предоставляет определенную разметку веб-дискурса, из которой можно определенными эвристиками получить корпус для извлечения структуры и полемической позиции аргументации.

В более ранних работах встречались небольшие корпуса из очень узких тематических областей. В работах \cite{palau2009argumentation, ronzano2015dr} предоставлена схожая разметка в юридических документах и научных статьях соответственно. Разметка представляет с собой связи между предложениями внутри текстов - как предложения поддерживают друг друга, чтобы итоговый текст был связным и убедительным. 

Дополнительно стоит отметить и примеры политической аргументации, содержащиеся в корпусе трека SemEval 2020 Task 11 Propaganda detection in news articles \cite{da2020semeval}. В данном соревновании предлагается выделить участки новостных статей, содержащих аргументацию, а также классифицировать их в такие приемы, как ложная аналогия, подмена тезиса, эксплуатация двусмысленных выражений, сведение аргументации к универсально осуждаемой теме и другим приемам убеждения оппонента. Пропаганду также можно свести и к примерам "ложной" аргументации, так как она скорее нацелена убеждение читающего, а не на установление истины.

\subsection{Обзор существующих решений}

Было создано несколько систем для извлечения аргументации, работающих с различными постановками задачи.

Первая  рассматриваемая система MARGOT \cite{lippi2016margot} придерживается определений контекстно-зависимых утверждений и предпосылок из работы \cite{aharoni2014benchmark}. По заданной теме к тексту последовательно применяется несколько моделей - модель определения предложений, содержащих компоненты аргументации, и модель выделения компоненты внутри предложения, после чего компоненты аргументации связываются отношением поддержки. Предложенные модели основаны на методах машинного обучения над признаками, выделенными из синтаксиса предложений.

Система MARGOT решает задачу извлечения аргументации в одной из самых ранних постановок, от которой отказались в последующих работах. В данной постановке отсутствует отношение противоречия, что не позволяет полностью определить ни структуру, ни полемическую позицию аргументации. Более того в данной постановке дополнительно происходит выделение компонент аргументации внутри предложений, как коротких непрерывных участков фраз. От данной подзадачи впоследствии отказались в пользу решения задачи на уровне предложений.

Targer \cite{chernodub2019targer} - система направленная на анализ текстов с целью изучения их аргументационной структуры. В системе предлагается использовать подход классификации последовательностей слов (Sequence Tagging), подобный задаче распознавания именованных сущнностей, для разбиения текста на фразы и выделения связей между ними. Данная система работает в рамках определенного текста и не способна связывать произвольные компоненты аргументации, выделенные из различных источников.


ArgumentText \cite{daxenberger2020argumentext} - данная система отличается от предыдущих постановкой задачи. Вместо поиска участков текста, которые являются компонентами аргументации и выделения отношений между ними, производится поиск предложений, напрямую поддерживающих или опровергающих тему. ArgumenText представляет собой многоступенчатую систему извлечения аргументации, в рамках которой решается и задача кластеризации утверждений по теме, поиск и классификация релевантных документов.


\subsection{Вывод}
Как видно из обзора работ существует множество подходов к задаче извлечения аргументации, как и существует несколько постановок. Также есть и ряд подзадач, таких как верификация и ранжирование утверждений по качеству или определение противоричивости темы.

Основными критериями для выбора корпусов служили следующие критерии:

\begin{itemize}
    \item Возможность напрямую решать или задачу определения структуры или определения полемической позиции аргументации. В то время как сущетсвует множество различных постановок задачи извлечения аргументации, а так же вспомогательных задач, в рамках данной работы было решено сфокусироваться на основных задачах извлечения аргументации.
    \item Возможность сравнить свое модельное решение с заявленными метриками качества. Некоторые работы или не имеют заявленных чисел или имеют невоспроизводимые результаты (замеры качества с помощью экспертов), или используют в обучении дополнительные закрытые наборы данных, которые не позволяют адекватно сравнить полученные системы.
\end{itemize}

По этим причинам были выбраны следующие корпуса:
\begin{enumerate}
    \item Новостной корпус пропаганды из соревнования SemEval \cite{da2020semeval}.
    \item Корпус для построения структуры аргументации IBM Evidence Search из работы  \cite{shnarch2018will}
    \item Корпус для определения полемической позиции ArgsEN и корпус для одновременного определения полемической позиции и структуры аргументации EviEN из работы \cite{toledo2020multilingual}.
    \item Корпус из задачи логического вывода SNLI \cite{snli:emnlp2015} для исследования применимости закономерностей, выученных на задаче логического вывода в задаче извлечения аргументации.
    \item Корпус задачи логического вывода TERRA на русском языке
\end{enumerate}


